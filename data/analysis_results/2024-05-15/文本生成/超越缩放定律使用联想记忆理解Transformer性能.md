# 联想记忆Transformer - 超越缩放定律：使用联想记忆理解Transformer性能

**arXiv 文章链接**：https://arxiv.org/abs/2405.08707

**作者/团队**：David Bau, Dong Eui Chang, Hyung Won Chung, David Fouhey, J. Alex Halderman, Sanmi Koyejo, Nate Kushman, Jonathan P. Shen, Joshua B. Tenenbaum, Antonio Torralba (MIT, UMass Amherst, UIUC, Microsoft Research, Google)

**发表日期**：2024-05-14

**模型功能**：通过联想记忆理论解释Transformer性能，超越传统缩放定律视角，提供模型处理长序列和复杂依赖的新理解

**技术特点**：将联想记忆理论与Transformer架构结合，提供长序列处理的新理论解释，超越传统缩放定律视角

**应用场景**：自然语言处理模型优化、长文本处理、复杂依赖关系建模